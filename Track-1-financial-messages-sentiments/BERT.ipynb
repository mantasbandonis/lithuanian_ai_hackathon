{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import ipdb\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT parameters\n",
    "bert_tokenizer_model_id = 'bert-base-uncased'\n",
    "# bert_pretrained_model_id = 'google/bert_uncased_L-2_H-128_A-2' # tiny\n",
    "# bert_pretrained_model_id = 'google/bert_uncased_L-4_H-256_A-4' # mini\n",
    "# bert_pretrained_model_id = 'google/bert_uncased_L-4_H-512_A-8' # small\n",
    "# bert_pretrained_model_id = 'google/bert_uncased_L-8_H-512_A-8' # medium\n",
    "bert_pretrained_model_id = 'google/bert_uncased_L-12_H-768_A-12' # base\n",
    "\n",
    "## other training parameters\n",
    "max_doc_length = 256   # max in train data is 62 in main and 258 in extra data\n",
    "clip = 0.25            #gradient clipping\n",
    "lr = 0.00003           #initial learning rate\n",
    "wdecay=1.2e-6          #weight decay applied to all weights\n",
    "epochs = 30            #maximum number of epochs\n",
    "batch_size = 4         #batch size\n",
    "save = 'model.pt'      #path to save the final model\n",
    "use_extra_data = True  #if extra data should be used\n",
    "\n",
    "train_max_number_batches = -1 # only for the sake of debugging. Set to -1 to be ignored\n",
    "inference_max_number_batches = -1 # only for the sake of debugging. Set to -1 to be ignored\n",
    "\n",
    "## log parameters\n",
    "log_interval = 100     #log interval during training\n",
    "log_interval_val = 100 #log interval during validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch:\n",
      "1 GPU(s) available.\n",
      "GPU-Name: A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch GPU capabilities:\n",
    "\n",
    "print(\"\\nPyTorch:\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('%d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('GPU-Name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data, tokenization, and loading into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcaptions = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "df = pd.read_csv('./all-data.csv', header=None, sep=\",\", encoding='ISO-8859-1', names=[\"label\",\"text\"])\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: labelcaptions[x])\n",
    "df[\"sentence_id\"] = np.array(list(range(len(df))))\n",
    "\n",
    "df_extra = pd.read_csv('./public-test-set.csv', header=None, sep=\",\", encoding='UTF-8', names=[\"label\",\"text\"])\n",
    "df_extra[\"label\"] = df_extra[\"label\"].apply(lambda x: {\"negative\": 0, \"neutral\": 1, \"positive\": 2}[x])\n",
    "df_extra[\"sentence_id\"] = np.array(list(range(len(df),len(df)+len(df_extra))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "test_size = 0\n",
    "assert train_size + val_size + test_size == 1.\n",
    "\n",
    "train_ind = slice(0,int(len(df)*train_size))\n",
    "val_ind = slice(int(len(df)*train_size),int(len(df)*train_size)+int(len(df)*val_size))\n",
    "test_ind = slice(int(len(df)*train_size)+int(len(df)*val_size),int(len(df)*train_size)+int(len(df)*val_size)++int(len(df)*test_size))\n",
    "\n",
    "# Shuffle\n",
    "df_shuffle = df.sample(frac=1)\n",
    "\n",
    "# Split\n",
    "df_train_, df_val, df_test = df_shuffle[train_ind], df_shuffle[val_ind], df_shuffle[test_ind]\n",
    "df_train_[\"label\"] = df_train_[\"label\"].to_numpy().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_df(df1, df2):\n",
    "    labels = np.array(list(df1[\"label\"].to_numpy()) + list(df2[\"label\"].to_numpy()))\n",
    "    texts = np.array(list(df1[\"text\"].to_numpy()) + list(df2[\"text\"].to_numpy()))\n",
    "    df = pd.DataFrame({\"label\":labels, \"text\":texts})\n",
    "    df[\"sentence_id\"] = np.array(list(range(len(df))))\n",
    "    df = df.sample(frac=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      label                                               text  sentence_id\n",
       " 8205      2  $TSLA  i honestly figured she would trade inde...         8205\n",
       " 7076      2                                          $PHIO big         7076\n",
       " 4014      1               $AAPL y’all see that 6000 sell. Ouch         4014\n",
       " 8976      2  $ZSAN alright fam in at 68 with 3k shares, let...         8976\n",
       " 2521      2  Operating profit of Kauppalehti group rose to ...         2521\n",
       " ...     ...                                                ...          ...\n",
       " 6976      1                                    $OPK hell yeah!         6976\n",
       " 5521      2  @Californiamaster  Unlike most internet compan...         5521\n",
       " 7673      2  $SRNE WILL BE OVER 20.00 SHORTLY AFTER PR DROP...         7673\n",
       " 7217      2  $SE twice it touch 160, the 3rd time will be b...         7217\n",
       " 7121      2  $PSTI President Trump Will Be Trumpeting Thera...         7121\n",
       " \n",
       " [8994 rows x 3 columns],\n",
       " 258)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_extra_data: df_train = get_extended_df(df_train_, df_extra)\n",
    "else: df_train = df_train_\n",
    "df_train, df_train[\"text\"].apply(lambda x: len(x.split(\" \"))).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'a', 'dec', '##eptive', '##ly', 'simple', 'premise', ',', 'this', 'deeply', 'moving', 'french', 'drama', 'develops', 'a', 'startling', 'story', 'that', 'works', 'both', 'as', 'a', 'detailed', 'personal', 'portrait', 'and', 'as', 'a', 'rather', 'frightening', 'examination', 'of', 'modern', 'times', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_tokenizer_model_id, do_lower_case=True)\n",
    "\n",
    "# sample subword tokenization\n",
    "_sample_text = 'From a deceptively simple premise , this deeply moving French drama develops a startling story that works both as a detailed personal portrait and as a rather frightening examination of modern times .'\n",
    "print (tokenizer.tokenize(_sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ي'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{id:word for word, id in tokenizer.get_vocab().items()}[1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2013,  1037, 11703, 22048,  2135,  3722, 18458,  1010,  2023,\n",
      "          6171,  3048,  2413,  3689, 11791,  1037, 19828,  2466,  2008,  2573,\n",
      "          2119,  2004,  1037,  6851,  3167,  6533,  1998,  2004,  1037,  2738,\n",
      "         17115,  7749,  1997,  2715,  2335,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037, 13012, 21031,  1997,  1037,  3185,\n",
      "          1010,  2007,  1037,  2261, 11680,  4193,  2019,  4895, 28578, 17007,\n",
      "          3085,  3730,  2415,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "def convert_text_bertids_tensor(texts):\n",
    "    #### complete the code (1 point) - START ####\n",
    "    # do tokenization here and return a dictionary, containing tensors of 'input_ids', 'token_type_ids', and 'attention_mask'\n",
    "    # the result looks like the following dictionary for the samples below\n",
    "    #{'input_ids': tensor([[  101,  2013,  1037, 11703, 22048,  2135,  3722, 18458,  1010,  2023,\n",
    "    #      6171,  3048,  2413,  3689, 11791,  1037, 19828,  2466,  2008,  2573,\n",
    "    #      2119,  2004,  1037,  6851,  3167,  6533,  1998,  2004,  1037,  2738,\n",
    "    #     17115,  7749,  1997,  2715,  2335,  1012,   102],\n",
    "    #    [  101,  2009,  1005,  1055,  1037, 13012, 21031,  1997,  1037,  3185,\n",
    "    #      1010,  2007,  1037,  2261, 11680,  4193,  2019,  4895, 28578, 17007,\n",
    "    #      3085,  3730,  2415,  1012,   102,     0,     0,     0,     0,     0,\n",
    "    #         0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    #     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    #    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    #     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "    #     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    #    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "    #     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
    "    \n",
    "    \n",
    "    #### complete the code - END ####\n",
    "\n",
    "    return tokenizer(texts, padding=True, return_tensors=\"pt\", truncation=True, max_length=max_doc_length)\n",
    "\n",
    "# sample\n",
    "_sample_text1 = 'From a deceptively simple premise , this deeply moving French drama develops a startling story that works both as a detailed personal portrait and as a rather frightening examination of modern times .'\n",
    "_sample_text2 = \"It 's a trifle of a movie , with a few laughs surrounding an unremarkable soft center .\"\n",
    "print (convert_text_bertids_tensor([_sample_text1, _sample_text2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data items: torch.Size([8994, 256]) (8994,)\n",
      "Validation data items: torch.Size([969, 80]) (969,)\n"
     ]
    }
   ],
   "source": [
    "def get_document_label_tensor(df):\n",
    "    documents = []\n",
    "    for x in df['text'].values:\n",
    "        documents.append(x.strip())\n",
    "    labels = np.array(list(df['label'].values))\n",
    "    data = convert_text_bertids_tensor(documents)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "x_train, y_train = get_document_label_tensor(df_train)\n",
    "print ('Train data items:', str(x_train['input_ids'].shape), str(y_train.shape))\n",
    "\n",
    "x_val, y_val = get_document_label_tensor(df_val)\n",
    "print ('Validation data items:', str(x_val['input_ids'].shape), str(y_val.shape))\n",
    "\n",
    "# x_test, y_test = get_document_label_tensor(df_test)\n",
    "# print ('Test data items:', str(x_test['input_ids'].shape), str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders \n",
    "dataset_train = TensorDataset(x_train['input_ids'], x_train['token_type_ids'], x_train['attention_mask'], torch.LongTensor(y_train))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=7, drop_last=True)\n",
    "\n",
    "dataset_val = TensorDataset(x_val['input_ids'], x_val['token_type_ids'], x_val['attention_mask'], torch.LongTensor(y_val))\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers=7, drop_last=True)\n",
    "\n",
    "dataset_test = dataset_val #TensorDataset(x_test['input_ids'], x_test['token_type_ids'], x_test['attention_mask'], torch.LongTensor(y_test))\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=7, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(fn, model, criterion, optimizer):\n",
    "    with open(fn, 'wb') as f:\n",
    "        torch.save([model.state_dict(), criterion.state_dict(), optimizer.state_dict()], f)\n",
    "\n",
    "def model_load(fn):\n",
    "    with open(fn, 'rb') as f:\n",
    "        model_state, criterion_state, optimizer_state = torch.load(f)\n",
    "    return model_state, criterion_state, optimizer_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifierModel(torch.nn.Module):\n",
    "    '''\n",
    "    Classification model with BERT\n",
    "    '''\n",
    "    def __init__(self, bert, nout):\n",
    "        super(BERTClassifierModel, self).__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        self.embedding_size = self.bert.config.hidden_size \n",
    "\n",
    "        self.output_projection_layer = torch.nn.Linear(self.embedding_size, nout)\n",
    "\n",
    "    '''\n",
    "    input format: seq_len, batch\n",
    "    '''\n",
    "    def forward(self, input_batch):       \n",
    "        #### complete the code (2 points) - START ####\n",
    "        # use the contents of `input_batch`, and pass them as parameters to self.bert\n",
    "        # use the output of BERT together with self.output_projection_layer to provide predictions \n",
    "        # the final results should consist of two variables:\n",
    "        #   `log_probs` -> tensor of logarithms of the predicted probabilities for classes \n",
    "        #   `final_representations` -> tensor of the output BERT vectors, based on which the prediction is done (for visualization purposes) \n",
    "        \n",
    "        _out = self.bert.forward(input_ids=input_batch[\"input_ids\"], attention_mask=input_batch[\"attention_mask\"], token_type_ids=input_batch[\"token_type_ids\"])\n",
    "        \n",
    "        final_representations = _out[\"last_hidden_state\"][:,0,:]\n",
    "        logits = self.output_projection_layer(final_representations)\n",
    "        #ipdb.set_trace()\n",
    "        \n",
    "        log_probs = torch.nn.LogSoftmax(dim=1)(logits)\n",
    "\n",
    "        #### complete the code - END ####\n",
    "        \n",
    "        return log_probs, final_representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([256, 4])\n",
      "output shape: torch.Size([256, 4])\n",
      "representations shape: torch.Size([256, 768])\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "## DUMMY TEST\n",
    "bert = BertModel.from_pretrained(bert_pretrained_model_id, cache_dir=\"cache\")\n",
    "_model = BERTClassifierModel(bert=bert, nout=4)\n",
    "_input_ids = torch.LongTensor(np.random.randint(low=0, high=1000, size=(max_doc_length, batch_size)))\n",
    "_token_type_ids = torch.LongTensor(np.zeros(shape=(max_doc_length, batch_size)))\n",
    "_attention_mask = torch.LongTensor(np.ones(shape=(max_doc_length, batch_size)))\n",
    "print ('input_ids shape: %s' % str(_input_ids.shape))\n",
    "_input_batch = {'input_ids': _input_ids, 'token_type_ids': _token_type_ids, 'attention_mask': _attention_mask}\n",
    "_output, _representations = _model.forward(_input_batch)\n",
    "print ('output shape: %s' % str(_output.shape))\n",
    "print ('representations shape: %s' % str(_representations.shape))\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BERTClassifierModel(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_projection_layer): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained(bert_pretrained_model_id, cache_dir=\"cache\", output_attentions=True)\n",
    "\n",
    "model = BERTClassifierModel(bert=bert, nout=len(labelcaptions.keys()))\n",
    "model.to(device)\n",
    "print('Model:', model)\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "params = list(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=wdecay)\n",
    "\n",
    "stored_res = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X): return [np.exp(x) / np.sum(np.exp(x)) for x in X]\n",
    "\n",
    "def predict(dataloader, model):\n",
    "    \n",
    "    model.to(device)\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    _predictions = []\n",
    "    _outputs = []\n",
    "    _labels = []\n",
    "    _representations = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        _input_ids, _token_type_ids, _attention_mask, _label = [e.to(device) for e in batch]\n",
    "        _input_batch = {'input_ids': _input_ids,\n",
    "                        'token_type_ids': _token_type_ids, \n",
    "                        'attention_mask': _attention_mask}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _output, _batch_representations = model.forward(_input_batch)\n",
    "            _batch_predictions = torch.argmax(_output, dim=1)\n",
    "        _outputs.extend(softmax(_output.cpu().numpy()))\n",
    "        _predictions.extend(_batch_predictions.cpu().numpy())\n",
    "        _labels.extend(_label.cpu().numpy())\n",
    "        _representations.extend(_batch_representations.cpu().numpy())\n",
    "        \n",
    "        if i % log_interval_val == 0 and i > 0:\n",
    "            print('Prediction | %5d batches | %5d data |' % (i, i*batch_size))\n",
    "            \n",
    "        if (i > inference_max_number_batches) and (inference_max_number_batches != -1):\n",
    "            break\n",
    "            \n",
    "    return _predictions, _outputs, _labels, np.array(_representations)\n",
    "\n",
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.to(device)\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    log_interval_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        _input_ids, _token_type_ids, _attention_mask, _label = [e.to(device) for e in batch]\n",
    "        _input_batch = {'input_ids': _input_ids,\n",
    "                        'token_type_ids': _token_type_ids, \n",
    "                        'attention_mask': _attention_mask}\n",
    "        \n",
    "        #### complete the code (2 points) - START ####\n",
    "        # here the actual training happens. Required steps:\n",
    "        #  forward pass\n",
    "        #  calculating loss\n",
    "        #  back-propagation\n",
    "        #  updating parameters\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _output, _ = model.forward(_input_batch)\n",
    "        \n",
    "        loss = criterion(_output, _label)\n",
    "        loss.backward()\n",
    "        \n",
    "        if clip:\n",
    "            torch.nn.utils.clip_grad_norm_(params, clip)\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        #### complete the code - END ####\n",
    "        \n",
    "        log_interval_loss += loss.item()\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = log_interval_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d} batches | {:5d} data | ms/batch {:5.2f} | loss {:5.3f}'.\n",
    "                  format(epoch, i, i*batch_size, elapsed * 1000 / log_interval, cur_loss))\n",
    "            log_interval_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "        if (i > train_max_number_batches) and (train_max_number_batches != -1):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "Start training\n",
      "| epoch   1 |   100 batches |   400 data | ms/batch 73.89 | loss 1.004\n",
      "| epoch   1 |   200 batches |   800 data | ms/batch 58.16 | loss 0.840\n",
      "| epoch   1 |   300 batches |  1200 data | ms/batch 58.28 | loss 0.857\n",
      "| epoch   1 |   400 batches |  1600 data | ms/batch 58.00 | loss 0.771\n",
      "| epoch   1 |   500 batches |  2000 data | ms/batch 54.73 | loss 0.707\n",
      "| epoch   1 |   600 batches |  2400 data | ms/batch 57.39 | loss 0.776\n",
      "| epoch   1 |   700 batches |  2800 data | ms/batch 56.44 | loss 0.616\n",
      "| epoch   1 |   800 batches |  3200 data | ms/batch 55.66 | loss 0.671\n",
      "| epoch   1 |   900 batches |  3600 data | ms/batch 57.16 | loss 0.689\n",
      "| epoch   1 |  1000 batches |  4000 data | ms/batch 55.33 | loss 0.666\n",
      "| epoch   1 |  1100 batches |  4400 data | ms/batch 56.18 | loss 0.664\n",
      "| epoch   1 |  1200 batches |  4800 data | ms/batch 57.67 | loss 0.717\n",
      "| epoch   1 |  1300 batches |  5200 data | ms/batch 55.13 | loss 0.644\n",
      "| epoch   1 |  1400 batches |  5600 data | ms/batch 53.88 | loss 0.678\n",
      "| epoch   1 |  1500 batches |  6000 data | ms/batch 53.87 | loss 0.695\n",
      "| epoch   1 |  1600 batches |  6400 data | ms/batch 54.85 | loss 0.729\n",
      "| epoch   1 |  1700 batches |  6800 data | ms/batch 55.63 | loss 0.669\n",
      "| epoch   1 |  1800 batches |  7200 data | ms/batch 56.87 | loss 0.595\n",
      "| epoch   1 |  1900 batches |  7600 data | ms/batch 54.94 | loss 0.724\n",
      "| epoch   1 |  2000 batches |  8000 data | ms/batch 55.36 | loss 0.631\n",
      "| epoch   1 |  2100 batches |  8400 data | ms/batch 56.26 | loss 0.654\n",
      "| epoch   1 |  2200 batches |  8800 data | ms/batch 54.12 | loss 0.724\n",
      "Epoch 1 validation\n",
      "Prediction |   100 batches |   400 data |\n",
      "Prediction |   200 batches |   800 data |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 130.94s | validation accuracy 0.823 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:274] . unexpected pos 63883968 vs 63883856",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5274d6d2c8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_res\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstored_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"models/BERT_valacc={val_res*100:.2f}%_bs={batch_size}_doc_len={max_doc_length}_epoch={epoch}_lr={lr}_valsize={val_size*100:.0f}_{bert_pretrained_model_id.split('/')[-1]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model (new best validation)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mstored_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b61e7f025679>\u001b[0m in \u001b[0;36mmodel_save\u001b[0;34m(fn, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 63883968 vs 63883856"
     ]
    }
   ],
   "source": [
    "print('=' * 89)\n",
    "print('Start training')\n",
    "\n",
    "EVAL_MEASURE = 'accuracy'\n",
    "\n",
    "\n",
    "# Loop over epochs.\n",
    "best_val_res = []\n",
    "try: stored_res = stored_res\n",
    "except: stored_res = 0\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(dataloader_train, model, criterion, optimizer)\n",
    "\n",
    "    print('Epoch %d validation' % epoch)\n",
    "    yhat, _, y, _ = predict(dataloader_val, model)\n",
    "    val_results = classification_report(y, yhat, output_dict=True)\n",
    "    val_res = val_results[EVAL_MEASURE]\n",
    "    \n",
    "    print('-' * 89)\n",
    "    print('| end of epoch %3d | time: %5.2fs | validation %s %.3f | ' % \n",
    "          (epoch, (time.time() - epoch_start_time), EVAL_MEASURE, val_res))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_res > stored_res:\n",
    "        save = f\"models/BERT_valacc={val_res*100:.2f}%_bs={batch_size}_doc_len={max_doc_length}_epoch={epoch}_lr={lr}_valsize={val_size*100:.0f}_{bert_pretrained_model_id.split('/')[-1]}\"\n",
    "        model_save(save, model, criterion, optimizer)\n",
    "        print('Saving model (new best validation)')\n",
    "        stored_res = val_res\n",
    "\n",
    "    best_val_res.append(val_res)\n",
    "print('End of training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "model_state, criterion_state, optimizer_state = model_load(save)\n",
    "model.load_state_dict(model_state)\n",
    "criterion.load_state_dict(criterion_state)\n",
    "optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "# Run on test data.\n",
    "yhat, yhat_proba, y, x_test_representations = predict(dataloader_test, model)\n",
    "results = classification_report(y, yhat, output_dict=True)\n",
    "print (classification_report(y, yhat))    \n",
    "\n",
    "print('=' * 89)\n",
    "print('| End of testing | test %s %.3f ' % (EVAL_MEASURE, results[EVAL_MEASURE]))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can somehow distinguish between positive and negative, but not very good\n",
    "scores = (yhat_proba * np.array([-1,0,1])).sum(axis=1)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.hist(scores[np.array(y)==0], color=\"red\", alpha=0.5,label=\"negative\", bins=30)\n",
    "plt.hist(scores[np.array(y)==1], color=\"gray\", alpha=0.5,label=\"neutral\", bins=30)\n",
    "plt.hist(scores[np.array(y)==2], color=\"green\", alpha=0.5,label=\"positive\", bins=30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range (cm.shape[0]):\n",
    "        for j in range (cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "tuples=[(key, value) for key, value in labelcaptions.items()]\n",
    "tuples.sort(key=lambda x: x[1])\n",
    "labelcaptions_inorder = [t[0] for t in tuples]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y, yhat)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "#plt.figure(figsize=(8,6))\n",
    "#plot_confusion_matrix(cnf_matrix, classes=labelcaptions_inorder,\n",
    "#                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labelcaptions_inorder, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
